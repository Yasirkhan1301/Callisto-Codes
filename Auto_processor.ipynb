{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe3da44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f9340",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Event list : ftp://ftp.swpc.noaa.gov/pub/warehouse/\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import glob\n",
    "from sys import stdout\n",
    "from time import sleep\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5aed22",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class variables:\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        self.s = \"/\"\n",
    "        self.types = [\"I\",\"II\",\"III\",\"IV\",\"V\",\"VI\"]\n",
    "        self.categories = [\"1\",\"2\",\"3\"]\n",
    "        self.year = kwargs[\"year\"]\n",
    "        self.month = kwargs[\"month\"]\n",
    "        self.day = kwargs[\"day\"]\n",
    "        self.dst = kwargs[\"dst\"]\n",
    "        self.src = kwargs[\"src\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0667ca0",
   "metadata": {
    "code_folding": [
     0,
     99,
     106,
     114
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Read_events:\n",
    "    \n",
    "    def __init__(self, d):\n",
    "        self.path = d.dst\n",
    "        self.year = str(d.year)\n",
    "        self.year_int = d.year\n",
    "        self.path2 = self.path+\"Event list/\" + self.year+\"_events/*.txt\"\n",
    "        self.types = d.types\n",
    "        self.categories = d.categories\n",
    "        self.s = d.s\n",
    "        self.path1 = d.dst\n",
    "        self.month = d.month\n",
    "        self.day = d.day\n",
    "        self.source  = d.src\n",
    "        \n",
    "    def extract_files(self): # only to extract .tar.gz file, it can be done with winrar or any other software manualy \n",
    "        # archive = self.year + '_events.tar.gz'\n",
    "        # tar = tarfile.open(archive, \"r:gz\")# download and put archive \n",
    "        # # file in the working directory   \n",
    "        # for member in tar.getmembers():\n",
    "        #     #print \"Extracting %s\" % member.name\n",
    "        #     tar.extract(member, path='')  \n",
    "        return False\n",
    "    \n",
    "    def find(self,name, path):#return root dir and name of a given file\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            if name in files:\n",
    "                return os.path.join(root, name) \n",
    "            \n",
    "    def fit_files_list(self):#this function save a list of all '.fit' files present in a given directory, in this case E drive.\n",
    "        fs = []\n",
    "        actual = []\n",
    "        fd = []\n",
    "        for root, dirs, files in os.walk(self.source): # change drive name \n",
    "            # select file name\n",
    "            for file in files:\n",
    "                # check the extension of files\n",
    "                if file.endswith('.fit'):\n",
    "                    # print whole path of files             \n",
    "                    fs.append(file.split('_'))\n",
    "                    fd.append(file)\n",
    "                    actual.append(file.split('.'))\n",
    "        d = pd.DataFrame(fs)\n",
    "        ds = pd.DataFrame(actual)\n",
    "        d[3],d[4] = ds[0] , fd\n",
    "        d.drop(d.index[d[1].isnull()], inplace = True)\n",
    "        d[5] = pd.to_datetime(d[1]).dt.date\n",
    "        d[1] = pd.to_datetime(d[1] + d[2])\n",
    "        d = d.set_index(d[1])\n",
    "        d.drop_duplicates(subset=[4],inplace = True)\n",
    "        d.index = d.index.floor('60min')\n",
    "        d.drop(labels = [1],inplace = True, axis = 1)\n",
    "        d.drop(d.index[d[3].str.contains(\" \")], inplace = True)\n",
    "        # d.to_csv(\"E:/CALLISTO/All_files_list.csv\" , index = True)\n",
    "        return d\n",
    "    \n",
    "    def read_files(self):# read extracted files, combine them in a dataframe\n",
    "        liste = glob.glob(self.path2)\n",
    "        df1 = []\n",
    "        for x in range (len(liste)-1):\n",
    "            #           Event   Begind    Max       End     Obs      \n",
    "            colspecs = [(0, 6),(10, 16), (18, 22),(27,32),(34,37),\n",
    "                        (38,40),(40,46),(48,52),(56,63),(65,73)]\n",
    "            #               Q     Type   Loc     Cat/type\n",
    "            df = pd.read_fwf(liste[x], colspecs=colspecs, header = None)\n",
    "            df.drop(\n",
    "                    labels = [0,1,2,3,4,5,6,7,8,9,10,11],\n",
    "                    axis = 0,\n",
    "                    inplace = True)\n",
    "            df.drop(\n",
    "                df.index[df[1].isnull()],\n",
    "                inplace = True)\n",
    "            xf = liste[x].split(\"\\\\\")\n",
    "            xf = xf[1].split(\".\")\n",
    "            xf = xf[0].replace(\"events\",\"\")\n",
    "            df[10] = xf\n",
    "            df\n",
    "            df1.append(df)\n",
    "            continue\n",
    "        return df1\n",
    "    \n",
    "    def search(self,index, category):#search index in parameters is for the end and begin timing column\n",
    "        dfs = self.read_files()\n",
    "        final = pd.concat(dfs)\n",
    "        final.drop(\n",
    "                final.index[final[index].isnull()],\n",
    "                inplace = True)\n",
    "        final.drop(\n",
    "            final.index[final[index].str.contains(\"[a-zA-Z]\")],#for removing alphabets\n",
    "            inplace = True\n",
    "            )\n",
    "        final[11] = final[10] + final[index]\n",
    "        final[11] = pd.to_datetime(final[11])\n",
    "        cat_3 = final[final[8] == category]\n",
    "        cat_3 = cat_3.set_index(cat_3[11])\n",
    "        cat_3 =  cat_3.between_time('00:30', '15:00')\n",
    "        cat_3.index = cat_3.index.floor('60min')\n",
    "        return cat_3\n",
    "    \n",
    "    def category(self,category):#return dataframe of category passed in the parameter\n",
    "        final_df = pd.concat([self.search(1,category),self.search(3,category)])\n",
    "        final_df.drop(labels = [11], axis = 1, inplace = True)\n",
    "        final_df.drop_duplicates(inplace = True)\n",
    "        final_df\n",
    "        return final_df\n",
    "    \n",
    "    def filter_by_time(self,g,category):# return the list of files present in the noaa solar events \n",
    "        d = g\n",
    "        d.index = pd.to_datetime(d.index)\n",
    "        cat = self.category(category).index\n",
    "        # d.index.isin(cat)# index number\n",
    "        file = d[d.index.isin(cat)]    \n",
    "        return file       \n",
    "    \n",
    "    def categorize(self):#access types and categories, and move files in directory tree pattern\n",
    "        g = self.fit_files_list()\n",
    "        counter = 0\n",
    "        for t in self.types:\n",
    "            for c in self.categories:\n",
    "                list_1 = self.filter_by_time(g,t+self.s+c)\n",
    "                length = len(list_1)\n",
    "                path = self.path1+self.s+self.year+self.s+t+self.s+c+self.s+\"Data\"\n",
    "                if exists(path) == False and length:\n",
    "                    os.makedirs(path)\n",
    "                for x in range (len(list_1)):     \n",
    "                    src = self.find(list_1[4][x], self.source)#Source Path\n",
    "                    dst = path +'/'+list_1[4][x]# Destination path\n",
    "                    shutil.copy(src, dst)\n",
    "                    counter +=1\n",
    "                    stdout.write(\"\\r%d Files copied \" % counter)\n",
    "                    stdout.flush()\n",
    "                    sleep(0.01)\n",
    "                    continue\n",
    "                    return 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f9891",
   "metadata": {
    "code_folding": [
     0,
     11,
     57
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class copy_files:\n",
    "    def __init__(self, d):\n",
    "        self.s = d.s\n",
    "        self.year = d.year\n",
    "        self.month = d.month\n",
    "        self.day = d.day\n",
    "        self.path = d.dst\n",
    "        self.fit_files_list = Read_events(d).fit_files_list\n",
    "        self.find = Read_events(d).find\n",
    "        self.source = d.src\n",
    "  \n",
    "    def copy(self, li,path):\n",
    "        counter = 0\n",
    "        path2 = path\n",
    "        if exists(path2) == False:\n",
    "            os.makedirs(path2)   \n",
    "        for x in range (len(li)):     \n",
    "            src = self.find(li[4][x], self.source)#Source Path\n",
    "            dst = path2 +'/'+li[4][x]# Destination path\n",
    "            shutil.copy(src, dst)\n",
    "            counter +=1\n",
    "            stdout.write(\"\\r%d Files copied \" % counter)\n",
    "            stdout.flush()\n",
    "            sleep(0.01)\n",
    "            continue   \n",
    "\n",
    "    def yearly(self):\n",
    "        path2 = self.path+str(self.year)+self.s+\"All Files\"\n",
    "        li = self.fit_files_list()\n",
    "        li = li[li.index.year == self.year]\n",
    "        self.copy(li,path2)        \n",
    "\n",
    "    def monthly(self):\n",
    "        path2 = self.path+self.year+self.s+str(self.month)+ self.s+\"Data\"\n",
    "        li = self.fit_files_list()\n",
    "        li = li[li.index.year == self.year]\n",
    "        li = li[li.index.month == self.month]\n",
    "        self.copy(li, path2)\n",
    "\n",
    "    def specified_date(self):\n",
    "        path2 = self.path+str(self.year)+self.s+str(self.month)+ self.s+str(self.day)+self.s+\"Data\"\n",
    "        li = self.fit_files_list()\n",
    "        li = li[li.index.year == self.year]\n",
    "        li = li[li.index.month == self.month]\n",
    "        li = li[li.index.day == self.day]\n",
    "        self.copy(li, path2)\n",
    "        \n",
    "    def date_range(self,start, end): \n",
    "        path = self.path+\"Daily_Overview\"+self.s+start +\"_to_\" + end+ self.s+self.s+\"Data\"\n",
    "        per = pd.date_range(start = start, end =end, freq ='D')\n",
    "        df = pd.DataFrame()\n",
    "        df[1] = per.date\n",
    "        df = df.set_index(df[1])\n",
    "        li = self.fit_files_list()\n",
    "        df = li[li[5].isin(df.index)]\n",
    "        return df,path   \n",
    "    \n",
    "    def folder_maker(self,d,path):\n",
    "        while len(d)>0:\n",
    "            x = d[d[5] == d[5][1]] \n",
    "            date = x[5][1].strftime(\"%m-%d-%Y\")#pls make it (YY-mm-dd) for future use\n",
    "            path1 = path +self.s+date\n",
    "            if exists(path1) == False:\n",
    "                os.makedirs(path1)  \n",
    "            self.copy(x,path1)\n",
    "            d = d.loc[d.index.difference(x.index)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c01cb",
   "metadata": {
    "code_folding": [
     29
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Daily_Overview:\n",
    "    def __init__(self, **kwargs):        \n",
    "        self.path = kwargs[\"data_path\"]\n",
    "        self.ID = kwargs[\"station\"]\n",
    "        self.FC = kwargs[\"code\"]\n",
    "        self.dst = kwargs[\"dst\"]\n",
    "        \n",
    "    def filter(self, path, date):\n",
    "        FCe = '_'+self.FC+'.fit'\n",
    "        myfilter= path+self.ID+'_'+date[0:4]+date[5:7]+date[8:10]+'*'+FCe+'*'\n",
    "        liste = glob.glob(myfilter)\n",
    "        liste.sort()     \n",
    "        return liste\n",
    "    \n",
    "    def files(self):\n",
    "        list = []\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            list.append(dirs)\n",
    "        list = list[0]\n",
    "        for i in range(len(list)):\n",
    "            path = self.path +\"\\\\\"+ list[i]+\"\\\\\"\n",
    "            date = list[i]\n",
    "            liste = self.filter(path, date)\n",
    "            try:\n",
    "                self.daily_overview(liste,date) # date-code, instrument-code, focus-code\n",
    "            except:\n",
    "                print (\"Error, most probably one or more corrupt FIT-file(s): \",sys.exc_info())\n",
    "        return False\n",
    "\n",
    "    def daily_overview(self,liste,date):    \n",
    "        fig, axs = plt.subplots(4, 16, figsize=(21,8), sharex=True, sharey=True)  \n",
    "        axs = axs.flatten() #from grid to flat list\n",
    "        FCe = '_'+self.FC+'.fit'\n",
    "        i = 0\n",
    "#         myfilter= path+self.ID+'_'+date[0:4]+date[5:7]+date[8:10]+'*'+FCe+'*'\n",
    "#         liste = glob.glob(myfilter)\n",
    "        liste.sort()\n",
    "        for ffile in liste:\n",
    "            if FCe in ffile:\n",
    "                hdu = fits.open(ffile)\n",
    "                S = hdu[0].data\n",
    "                n  = 30*4 # position in time for background analysis\n",
    "                dn = 7 # number of spectra to average\n",
    "                spec = S[:,n:n+dn] # take a slice of a clean part\n",
    "                size = spec.shape\n",
    "                columns = size[0]\n",
    "                background = np.mean(spec,axis=1).reshape(columns,1)\n",
    "                data = S - background\n",
    "                data = data.clip(-1,50) # 30 adjust color-map (0dB = blue)\n",
    "                freq = hdu[1].data[0][1] # frequency axis\n",
    "                date = hdu[0].header['DATE-OBS']\n",
    "                Thour = int(hdu[0].header['TIME-OBS'].split(\":\")[0])\n",
    "                Tmin  = int(hdu[0].header['TIME-OBS'].split(\":\")[1])\n",
    "                p = int(int(Thour*60+Tmin)/15 + 0.5)\n",
    "                extent = (0,1, freq[-1], freq[0])\n",
    "                axs[p].imshow(data, aspect=\"auto\", extent=extent)\n",
    "                axs[p].set_xticks([])                #axs[p].axis('off')\n",
    "                i=i+1\n",
    "                hdu.close()\n",
    "\n",
    "        txt = '00            15             30             45              '\n",
    "        xaxistxt = txt + txt + txt + txt + txt \n",
    "        fig.text(0.12, 0.07, xaxistxt, ha='left',fontsize=10.5)\n",
    "        fig.text(0.055, 0.5, 'Frequency [MHz]', va='center', rotation='vertical', fontsize=15)\n",
    "        fig.text(0.91, 0.84, '00-03UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.71, '04-07UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.58, '08-11UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.45, '12-15UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.32, '16-19UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.19, '20-23UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.subplots_adjust(wspace=0.001, hspace=0.1)\n",
    "   \n",
    "        save_path = self.dst+\"\\\\\"+date[0:4]+date[5:7]+date[8:10]+'.png'\n",
    "        print(save_path)\n",
    "        plt.suptitle(\"Full day spectra \"+date+\" station: \"+self.ID+' with focus-code: '+self.FC, size=16)\n",
    "        plt.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = Daily_Overview(**arguments)\n",
    "list1 = daily.files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9502af5",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arguments = {\n",
    "       \"data_path\":\"E:\\\\CALLISTO\\\\Daily_Overview\\\\01-01-2022_to_06-30-2022\\\\Data\",\n",
    "        \"code\":\"59\",\n",
    "        \"station\":\"MUPK\",\n",
    "        \"dst\" : \"E:\\\\CALLISTO\\\\2022\\\\01-01-2022_to_06-30-2022\\\\Plots\"\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125b674",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"year\" : 2022,\n",
    "        \"month\" : 1,\n",
    "        \"day\" : 1,\n",
    "        \"src\" : \"E:\\\\\",\n",
    "        \"dst\" : \"E:/CALLISTO/\"    \n",
    "}\n",
    "p = variables(**args)\n",
    "copy_file = copy_files(p)\n",
    "d , path = copy_file.date_range('01-01-2022','06-30-2022')\n",
    "copy_file.folder_maker(d,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09b80b",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For Advancement------> \n",
    "# import tempfile\n",
    "# import shutil\n",
    "# def temp_dir():\n",
    "#     with tempfile.TemporaryDirectory() as tmpdir:\n",
    "# #         print('Created temporary directory ', tmpdir)\n",
    "# #         os.path.exists(tmpdir)\n",
    "#         src = \"E:\\\\CALLISTO\\\\Daily_Overview\\\\2021\\\\2021-07-03\\\\MUPK_20210703_004500_59.fit\"\n",
    "#         dst = str(tmpdir)\n",
    "#         shutil.copy(src, dst)\n",
    "#         for root, dirs, files in os.walk(dst):\n",
    "#             print(files,tmpdir)\n",
    "\n",
    "        \n",
    "# temp_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f07645",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#Rename dir names wrt correct date format(YY,mm,dd)\n",
    "#os.chdir(r\"E:\\\\CALLISTO\\\\Daily_Overview\\\\01-01-2022_to_06-30-2022\\\\Data\\\\\")\n",
    "# liste = []\n",
    "# print()\n",
    "# for root, dirs, files in os.walk(os.getcwd()):\n",
    "#             liste.append(dirs)\n",
    "# # print(liste[0])\n",
    "# df = pd.DataFrame(liste[0])\n",
    "# liste = liste[0]\n",
    "# df[0] = pd.to_datetime(df[0])\n",
    "# df[0] = df[0].astype(str)\n",
    "# for x in range (len(df)):\n",
    "#     os.rename(liste[x],df[0][x])\n",
    " \n",
    "# print(liste[1], df[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4de89f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.85px",
    "left": "656px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
