{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f383ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6b05e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Event list : ftp://ftp.swpc.noaa.gov/pub/warehouse/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972f9340",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Libraries---\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import glob\n",
    "from sys import stdout\n",
    "from time import sleep\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import pyCallisto as pyc\n",
    "import pyCallisto_Utils as utils\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from ftplib import FTP\n",
    "import ftputil\n",
    "import urllib \n",
    "from urllib.request import urlopen\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc5aed22",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class variables:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.s = \"/\"\n",
    "        self.types = [\"I\",\"II\",\"III\",\"IV\",\"V\",\"VI\"]\n",
    "        self.categories = [\"1\",\"2\",\"3\"]\n",
    "        for key, value in kwargs.items():\n",
    "          setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0667ca0",
   "metadata": {
    "code_folding": [
     0,
     2,
     10,
     33,
     38,
     65,
     91,
     109,
     116,
     124
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Read_events(variables):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        super(Read_events,self).__init__(**kwargs)\n",
    "        self.path = self.dst\n",
    "        self.year_int = self.year\n",
    "        self.year = str(self.year)\n",
    "        self.path2 = self.path+\"Event list/\" + self.year+\"_events/*.txt\"\n",
    "        self.path1 = self.path\n",
    "        \n",
    "    def tarfile_extract(self):\n",
    "        \n",
    "        path = self.ftp_path+self.year+self.s\n",
    "        try : #if tarfile exists       \n",
    "            thetarfile = path+self.year+\"_\"+\"events.tar.gz\"\n",
    "            ftpstream = urllib.request.urlopen(thetarfile)\n",
    "            thetarfile = tarfile.open(fileobj=ftpstream, mode=\"r|gz\")\n",
    "            thetarfile.extractall(\"..\\Event list\")\n",
    "            print(\"Tarfile extracted successfully\")\n",
    "        except: #if tarfile does not exist in ftp server, look for events folder and retrieve all .txt files\n",
    "            hostname = path+self.year+\"_events\"\n",
    "            ftpstream = urllib.request.urlopen(hostname)\n",
    "            # ftpstream = urllib.request.urlretrieve(hostname,\"20220101events.txt\")\n",
    "            with urlopen(hostname) as response:\n",
    "                body = response.read().decode('utf-8')\n",
    "                df = pd.DataFrame(body.split('\\n')) \n",
    "            df[0] = df[0].str[55:73]\n",
    "            df[0].replace('', np.nan, inplace=True)\n",
    "            df.dropna(subset=[0], inplace=True)\n",
    "            print(df)\n",
    "        else:\n",
    "            print(\"FTP server problem\")\n",
    "        \n",
    "    def find(self,name, path):#return root dir and name of a given file\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            if name in files:\n",
    "                return os.path.join(root, name) \n",
    "            \n",
    "    def fit_files_list(self):#this function save a list of all '.fit' files present in a given directory, in this case E drive.\n",
    "        fs = []\n",
    "        actual = []\n",
    "        fd = []\n",
    "        for root, dirs, files in os.walk(self.src): # change drive name \n",
    "            # select file name\n",
    "            for file in files:\n",
    "                # check the extension of files\n",
    "                if file.endswith('.fit'):\n",
    "                    # print whole path of files             \n",
    "                    fs.append(file.split('_'))\n",
    "                    fd.append(file)\n",
    "                    actual.append(file.split('.'))\n",
    "        d = pd.DataFrame(fs)\n",
    "        ds = pd.DataFrame(actual)\n",
    "        d[3],d[4] = ds[0] , fd\n",
    "        d.drop(d.index[d[1].isnull()], inplace = True)\n",
    "        d[5] = pd.to_datetime(d[1]).dt.date\n",
    "        d[1] = pd.to_datetime(d[1] + d[2])\n",
    "        d = d.set_index(d[1])\n",
    "        d.drop_duplicates(subset=[4],inplace = True)\n",
    "        d.index = d.index.floor('60min')\n",
    "        d.drop(labels = [1],inplace = True, axis = 1)\n",
    "        d.drop(d.index[d[3].str.contains(\" \")], inplace = True)\n",
    "        # d.to_csv(\"E:/CALLISTO/All_files_list.csv\" , index = True)\n",
    "        return d\n",
    "    \n",
    "    def read_files(self):# read extracted files, combine them in a dataframe\n",
    "        self.tarfile_extract()\n",
    "        liste = glob.glob(self.path2)\n",
    "        df1 = []\n",
    "        for x in range (len(liste)-1):\n",
    "            #           Event   Begind    Max       End     Obs      \n",
    "            colspecs = [(0, 6),(10, 16), (18, 22),(27,32),(34,37),\n",
    "                        (38,40),(40,46),(48,52),(56,63),(65,73)]\n",
    "            #               Q     Type   Loc     Cat/type\n",
    "            df = pd.read_fwf(liste[x], colspecs=colspecs, header = None)\n",
    "            df.drop(\n",
    "                    labels = [0,1,2,3,4,5,6,7,8,9,10,11],\n",
    "                    axis = 0,\n",
    "                    inplace = True)\n",
    "            df.drop(\n",
    "                df.index[df[1].isnull()],\n",
    "                inplace = True)\n",
    "            xf = liste[x].split(\"\\\\\")\n",
    "            xf = xf[1].split(\".\")\n",
    "            xf = xf[0].replace(\"events\",\"\")\n",
    "            df[10] = xf\n",
    "            df\n",
    "            df1.append(df)\n",
    "            continue\n",
    "        return df1\n",
    "    \n",
    "    def search(self,index, category):#search index in parameters is for the end and begin timing column\n",
    "        dfs = self.read_files()\n",
    "        final = pd.concat(dfs)\n",
    "        final.drop(\n",
    "                final.index[final[index].isnull()],\n",
    "                inplace = True)\n",
    "        final.drop(\n",
    "            final.index[final[index].str.contains(\"[a-zA-Z]\")],#for removing alphabets\n",
    "            inplace = True\n",
    "            )\n",
    "        final[11] = final[10] + final[index]\n",
    "        final[11] = pd.to_datetime(final[11])\n",
    "        cat_3 = final[final[8] == category]\n",
    "        cat_3 = cat_3.set_index(cat_3[11])\n",
    "        cat_3 =  cat_3.between_time('00:30', '15:00')\n",
    "        cat_3.index = cat_3.index.floor('60min')\n",
    "        return cat_3\n",
    "    \n",
    "    def category(self,category):#return dataframe of category passed in the parameter\n",
    "        final_df = pd.concat([self.search(1,category),self.search(3,category)])\n",
    "        final_df.drop(labels = [11], axis = 1, inplace = True)\n",
    "        final_df.drop_duplicates(inplace = True)\n",
    "        final_df\n",
    "        return final_df\n",
    "    \n",
    "    def filter_by_time(self,g,category):# return the list of files present in the noaa solar events \n",
    "        d = g\n",
    "        d.index = pd.to_datetime(d.index)\n",
    "        cat = self.category(category).index\n",
    "        # d.index.isin(cat)# index number\n",
    "        file = d[d.index.isin(cat)]    \n",
    "        return file       \n",
    "    \n",
    "    def categorize(self):#access types and categories, and move files in directory tree pattern\n",
    "        g = self.fit_files_list()\n",
    "        counter = 0\n",
    "        for t in self.types:\n",
    "            for c in self.categories:\n",
    "                list_1 = self.filter_by_time(g,t+self.s+c)\n",
    "                length = len(list_1)\n",
    "                path = self.path1+self.s+self.year+self.s+t+self.s+c+self.s+\"Data\"\n",
    "                if exists(path) == False and length:\n",
    "                    os.makedirs(path)\n",
    "                for x in range (len(list_1)):     \n",
    "                    src = self.find(list_1[4][x], self.source)#Source Path\n",
    "                    dst = path +'/'+list_1[4][x]# Destination path\n",
    "                    shutil.copy(src, dst)\n",
    "                    counter +=1\n",
    "                    stdout.write(\"\\r%d Files copied \" % counter)\n",
    "                    stdout.flush()\n",
    "                    sleep(0.01)\n",
    "                    continue\n",
    "                    return 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0f2d08",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-04 14:00:00</th>\n",
       "      <td>GREENLAND</td>\n",
       "      <td>140001</td>\n",
       "      <td>GREENLAND_20160504_140001_63</td>\n",
       "      <td>GREENLAND_20160504_140001_63.fit</td>\n",
       "      <td>2016-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>004500</td>\n",
       "      <td>MUPK_20220101_004500_59</td>\n",
       "      <td>MUPK_20220101_004500_59.fit</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>010000</td>\n",
       "      <td>MUPK_20220101_010000_59</td>\n",
       "      <td>MUPK_20220101_010000_59.fit</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>011500</td>\n",
       "      <td>MUPK_20220101_011500_59</td>\n",
       "      <td>MUPK_20220101_011500_59.fit</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>013000</td>\n",
       "      <td>MUPK_20220101_013000_59</td>\n",
       "      <td>MUPK_20220101_013000_59.fit</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 04:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>040259</td>\n",
       "      <td>MUPK_20220907_040259_59</td>\n",
       "      <td>MUPK_20220907_040259_59.fit</td>\n",
       "      <td>2022-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 04:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>041500</td>\n",
       "      <td>MUPK_20220907_041500_59</td>\n",
       "      <td>MUPK_20220907_041500_59.fit</td>\n",
       "      <td>2022-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 04:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>043000</td>\n",
       "      <td>MUPK_20220907_043000_59</td>\n",
       "      <td>MUPK_20220907_043000_59.fit</td>\n",
       "      <td>2022-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 04:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>044500</td>\n",
       "      <td>MUPK_20220907_044500_59</td>\n",
       "      <td>MUPK_20220907_044500_59.fit</td>\n",
       "      <td>2022-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07 05:00:00</th>\n",
       "      <td>MUPK</td>\n",
       "      <td>050000</td>\n",
       "      <td>MUPK_20220907_050000_59</td>\n",
       "      <td>MUPK_20220907_050000_59.fit</td>\n",
       "      <td>2022-09-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56520 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0       2                             3  \\\n",
       "1                                                                      \n",
       "2016-05-04 14:00:00  GREENLAND  140001  GREENLAND_20160504_140001_63   \n",
       "2022-01-01 00:00:00       MUPK  004500       MUPK_20220101_004500_59   \n",
       "2022-01-01 01:00:00       MUPK  010000       MUPK_20220101_010000_59   \n",
       "2022-01-01 01:00:00       MUPK  011500       MUPK_20220101_011500_59   \n",
       "2022-01-01 01:00:00       MUPK  013000       MUPK_20220101_013000_59   \n",
       "...                        ...     ...                           ...   \n",
       "2022-09-07 04:00:00       MUPK  040259       MUPK_20220907_040259_59   \n",
       "2022-09-07 04:00:00       MUPK  041500       MUPK_20220907_041500_59   \n",
       "2022-09-07 04:00:00       MUPK  043000       MUPK_20220907_043000_59   \n",
       "2022-09-07 04:00:00       MUPK  044500       MUPK_20220907_044500_59   \n",
       "2022-09-07 05:00:00       MUPK  050000       MUPK_20220907_050000_59   \n",
       "\n",
       "                                                    4           5  \n",
       "1                                                                  \n",
       "2016-05-04 14:00:00  GREENLAND_20160504_140001_63.fit  2016-05-04  \n",
       "2022-01-01 00:00:00       MUPK_20220101_004500_59.fit  2022-01-01  \n",
       "2022-01-01 01:00:00       MUPK_20220101_010000_59.fit  2022-01-01  \n",
       "2022-01-01 01:00:00       MUPK_20220101_011500_59.fit  2022-01-01  \n",
       "2022-01-01 01:00:00       MUPK_20220101_013000_59.fit  2022-01-01  \n",
       "...                                               ...         ...  \n",
       "2022-09-07 04:00:00       MUPK_20220907_040259_59.fit  2022-09-07  \n",
       "2022-09-07 04:00:00       MUPK_20220907_041500_59.fit  2022-09-07  \n",
       "2022-09-07 04:00:00       MUPK_20220907_043000_59.fit  2022-09-07  \n",
       "2022-09-07 04:00:00       MUPK_20220907_044500_59.fit  2022-09-07  \n",
       "2022-09-07 05:00:00       MUPK_20220907_050000_59.fit  2022-09-07  \n",
       "\n",
       "[56520 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling Read_events_files \n",
    "kwargs = {\n",
    "        \"year\" : 2022,\n",
    "        \"src\" : \"E:\\\\\",\n",
    "        \"dst\" : \"E:/CALLISTO/\",\n",
    "        \"ftp_path\" : \"ftp://ftp.swpc.noaa.gov/pub/warehouse/\"\n",
    "}\n",
    "v = Read_events(**kwargs)\n",
    "v.fit_files_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f9891",
   "metadata": {
    "code_folding": [
     0,
     7,
     22,
     28,
     35,
     43,
     53
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class copy_files(Read_events):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(copy_files,self).__init(**kwargs)\n",
    "        self.path = self.dst\n",
    "#         self.fit_files_list = self.fit_files_list\n",
    "#         self.find = self.find\n",
    "  \n",
    "    def copy(self, li,path):\n",
    "        counter = 0\n",
    "        path2 = path\n",
    "        if exists(path2) == False:\n",
    "            os.makedirs(path2)   \n",
    "        for x in range (len(li)):     \n",
    "            src = self.find(li[4][x], self.src)#Source Path\n",
    "            dst = path2 +'/'+li[4][x]# Destination path\n",
    "            shutil.copy(src, dst)\n",
    "            counter +=1\n",
    "            stdout.write(\"\\r%d Files copied \" % counter)\n",
    "            stdout.flush()\n",
    "            sleep(0.01)\n",
    "            continue   \n",
    "\n",
    "    def yearly(self):\n",
    "        path2 = self.path+str(self.year)+self.s+\"All Files\"\n",
    "        li = self.fit_files_list()\n",
    "        li = li[li.index.year == self.year]\n",
    "        self.copy(li,path2)        \n",
    "\n",
    "    def monthly(self):\n",
    "        path2 = self.path+self.year+self.s+str(self.month)+ self.s+\"Data\"\n",
    "        li = self.fit_files_list()\n",
    "        li = li[li.index.year == self.year]\n",
    "        li = li[li.index.month == self.month]\n",
    "        self.copy(li, path2)\n",
    "\n",
    "    def specified_date(self):\n",
    "        path2 = self.path+str(self.year)+self.s+str(self.month)+ self.s+str(self.day)+self.s+\"Data\"\n",
    "        li = self.fit_files_list()\n",
    "        li = li[li.index.year == self.year]\n",
    "        li = li[li.index.month == self.month]\n",
    "        li = li[li.index.day == self.day]\n",
    "        self.copy(li, path2)\n",
    "        \n",
    "    def date_range(self,start, end): \n",
    "        path = self.path+\"Daily_Overview\"+self.s+start +\"_to_\" + end+ self.s+self.s+\"Data\"\n",
    "        per = pd.date_range(start = start, end =end, freq ='D')\n",
    "        df = pd.DataFrame()\n",
    "        df[1] = per.date\n",
    "        df = df.set_index(df[1])\n",
    "        li = self.fit_files_list()\n",
    "        df = li[li[5].isin(df.index)]\n",
    "        return df,path   \n",
    "    \n",
    "    def dir_maker(self,d,path):\n",
    "        while len(d)>0:\n",
    "            x = d[d[5] == d[5][1]] \n",
    "            date = x[5][1].strftime(\"%Y-%m-%d\")#pls make it (YY-mm-dd) for future use\n",
    "            path1 = path +self.s+date\n",
    "            if exists(path1) == False:\n",
    "                os.makedirs(path1)  \n",
    "                self.copy(x,path1)\n",
    "            d = d.loc[d.index.difference(x.index)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125b674",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Copy files into a directory tree---\n",
    "args = {\n",
    "        \"year\" : 2022,\n",
    "        \"month\" : 1,\n",
    "        \"day\" : 1,\n",
    "        \"src\" : \"E:\\\\\",\n",
    "        \"dst\" : \"E:/CALLISTO/\"    \n",
    "}\n",
    "p = variables(**args)\n",
    "copy_file = copy_files(p)\n",
    "# d , path = copy_file.date_range('07-01-2022','09-09-2022')# mm-dd-yy\n",
    "copy_file.folder_maker(d,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d24e425",
   "metadata": {
    "code_folding": [
     0,
     1,
     6,
     22,
     31,
     37,
     43,
     50,
     74
    ]
   },
   "outputs": [],
   "source": [
    "class plot:\n",
    "    def __init__(self,year, path):\n",
    "        self.year = year\n",
    "        self.path = path#\"E:\\CALLISTO\"#data path\n",
    "        self.slash = \"/\"\n",
    "\n",
    "    def find(self,path):\n",
    "        file_list = []\n",
    "        for files in os.walk(path): \n",
    "            continue\n",
    "        files = files[2]\n",
    "        for file in files:\n",
    "            file_size = os.path.getsize(path +\"\\\\\"+file)\n",
    "            file_size = file_size/1000\n",
    "            if file_size >= 200:\n",
    "                file_list.append(file)\n",
    "            # files = find(path)\n",
    "        fit = pd.DataFrame(file_list)\n",
    "#         fit[1] = fit[0].str.replace(\".fit\", \"\")\n",
    "        fit[1] = fit[0].apply(lambda x: x.replace(\".fit\", \"\"))\n",
    "        return fit\n",
    "\n",
    "    def find_Data(self):      \n",
    "        x = []\n",
    "        start = self.path+self.slash+self.year\n",
    "        for dirpath, dirnames, filenames in os.walk(start):\n",
    "            for dirname in dirnames:\n",
    "                if dirname == \"Data\":              \n",
    "                    x.append(dirpath)\n",
    "        return x\n",
    "    \n",
    "    def simple(self,src, dst,name):\n",
    "            slash = \"/\"\n",
    "            fits1 = pyc.PyCallisto.from_file(src)\n",
    "            plt = fits1.spectrogram() #this will show in imshow thing\n",
    "            plt.savefig(dst+slash+name+\".png\")\n",
    "        \n",
    "    def files_in_dir(self, src,dst):\n",
    "        files = self.find(src)\n",
    "        for file in files():\n",
    "            simple(src, dst, file)\n",
    "            bg(src,dst,file)\n",
    "            \n",
    "    def bg(self, src, dst, name):\n",
    "        slash = \"/\"\n",
    "        fits1 = pyc.PyCallisto.from_file(src)\n",
    "        background_subtracted = fits1.subtract_background()\n",
    "        plt = background_subtracted.spectrogram()\n",
    "        plt.savefig(dst+slash+name+\"_bg_sub.png\")\n",
    "\n",
    "    def simple_plot(self):\n",
    "        dirs = self.find_Data()\n",
    "        dirs = pd.Series(dirs)        \n",
    "        for path in dirs:\n",
    "            path2 = path\n",
    "            path = path + \"/Data\"\n",
    "            fit = self.find(path)\n",
    "            #saving plots in this dir\n",
    "            path3 = path2 + \"\\Plots\"\n",
    "            if exists(path3) == False:            \n",
    "                os.mkdir(path3)    \n",
    "                fit = self.find(path)\n",
    "                if exists(path2) == False:\n",
    "                    os.mkdir(path2)                    \n",
    "                for x in range(len(fit)):    \n",
    "                    fit_path = path+self.slash+fit[0][x]\n",
    "                    print(x,\"Processing:\",fit[0][x])\n",
    "                    #plot multiple files\n",
    "                    dst = path3\n",
    "                    name = fit[1][x]\n",
    "                    self.simple(fit_path,dst,name)\n",
    "                    continue\n",
    "                    return False\n",
    "                \n",
    "    def bg_plot(self):\n",
    "        \n",
    "        dirs = self.find_Data()\n",
    "        dirs = pd.Series(dirs)\n",
    "        for path in dirs:\n",
    "            path2 = path\n",
    "            path = path + \"/Data\"\n",
    "            fit = self.find(path) \n",
    "            #saving plots in this dir\n",
    "            dst = path2 + \"\\Plots_bg_sub\"   \n",
    "            if exists(dst) == False:  \n",
    "                os.mkdir(dst)\n",
    "            for x in range(len(fit)):\n",
    "              fit_path = path+self.slash+fit[0][x]\n",
    "              print(x,\"Processing:\",fit[0][x])\n",
    "              self.bg(fit_path,dst,fit[1][x])\n",
    "#               print(fit_path,dst,fit[1][x])\n",
    "              continue\n",
    "              return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8451507",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Plot---\n",
    "# pl = plot(\"2022\", \"E:\\CALLISTO\")# year,its parent \"path\"\n",
    "# pl.simple_plot()\n",
    "# pl.bg_plot()\n",
    "# pl.bg(\n",
    "#     \"E:\\CALLISTO\\\\2022\\\\II\\\\1\\\\Data/MUPK_20220321_052400_59.fit\", \n",
    "#           \"E:\\CALLISTO\\Specific\",\n",
    "#           \"MUPK_20220321_052400_59\"\n",
    "# )\n",
    "# bg = plot.bg_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c01cb",
   "metadata": {
    "code_folding": [
     0,
     30,
     39
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Daily_Overview:\n",
    "    def __init__(self, **kwargs):        \n",
    "         for key, value in kwargs.items():\n",
    "          setattr(self, key, value)\n",
    "        \n",
    "    def filter(self, path, date):\n",
    "        FCe = '_'+self.FC+'.fit'\n",
    "        myfilter= path+self.ID+'_'+date[0:4]+date[5:7]+date[8:10]+'*'+FCe+'*'\n",
    "        liste = glob.glob(myfilter)\n",
    "        liste.sort()     \n",
    "        return liste\n",
    "    \n",
    "    def files(self):\n",
    "        list = []\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            list.append(dirs)\n",
    "        list = list[0]\n",
    "        for i in range(len(list)):\n",
    "            path = self.path +\"\\\\\"+ list[i]+\"\\\\\"\n",
    "            date = list[i]\n",
    "            liste = self.filter(path, date)\n",
    "            dst = self.dst+\"/\"+date[0:4]+date[5:7]+date[8:10]+'.png'\n",
    "            if exists(dst) == False:\n",
    "                print(dst)\n",
    "                try:\n",
    "                    self.daily_overview(liste,date,dst) # date-code, instrument-code, focus-code\n",
    "                except:\n",
    "                    print (\"Error, most probably one or more corrupt FIT-file(s): \",sys.exc_info())\n",
    "        return False\n",
    "\n",
    "    def daily_overview(self,liste,date,dst):  \n",
    "\n",
    "        fig, axs = plt.subplots(4, 16, figsize=(21,8), sharex=True, sharey=True)  \n",
    "        axs = axs.flatten() #from grid to flat list\n",
    "        FCe = '_'+self.FC+'.fit'\n",
    "#         print(liste[0], date,FCe)\n",
    "#         myfilter= path+self.ID+'_'+date[0:4]+date[5:7]+date[8:10]+'*'+FCe+'*'\n",
    "#         liste = glob.glob(myfilter)\n",
    "#         liste.sort()\n",
    "        for ffile in liste:\n",
    "            if FCe in ffile:\n",
    "                hdu = fits.open(ffile)\n",
    "                S = hdu[0].data\n",
    "                n  = 30*4 # position in time for background analysis\n",
    "                dn = 7 # number of spectra to average\n",
    "                spec = S[:,n:n+dn] # take a slice of a clean part\n",
    "                size = spec.shape\n",
    "                columns = size[0]\n",
    "                background = np.mean(spec,axis=1).reshape(columns,1)\n",
    "                data = S - background\n",
    "                data = data.clip(-1,50) # 30 adjust color-map (0dB = blue)\n",
    "                freq = hdu[1].data[0][1] # frequency axis\n",
    "                date = hdu[0].header['DATE-OBS']\n",
    "                Thour = int(hdu[0].header['TIME-OBS'].split(\":\")[0])\n",
    "                Tmin  = int(hdu[0].header['TIME-OBS'].split(\":\")[1])\n",
    "                p = int(int(Thour*60+Tmin)/15 + 0.5)\n",
    "                extent = (0,1, freq[-1], freq[0])\n",
    "                axs[p].imshow(data, aspect=\"auto\", extent=extent)\n",
    "                axs[p].set_xticks([])                #axs[p].axis('off')\n",
    "                hdu.close()\n",
    "                \n",
    "        txt = '00            15             30             45              '\n",
    "        xaxistxt = txt + txt + txt + txt + txt \n",
    "        fig.text(0.12, 0.07, xaxistxt, ha='left',fontsize=10.5)\n",
    "        fig.text(0.055, 0.5, 'Frequency [MHz]', va='center', rotation='vertical', fontsize=15)\n",
    "        fig.text(0.91, 0.84, '00-03UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.71, '04-07UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.58, '08-11UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.45, '12-15UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.32, '16-19UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.text(0.91, 0.19, '20-23UT', va='center', rotation='horizontal', fontsize=15)\n",
    "        fig.subplots_adjust(wspace=0.001, hspace=0.1)\n",
    "        plt.suptitle(\"Full day spectra \"+date+\" station: \"+self.ID+' with focus-code: '+self.FC, size=16)\n",
    "        plt.savefig(dst)\n",
    "        print(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9502af5",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot daily overview plotting---\n",
    "arguments = {\n",
    "       \"path\":\"E:\\\\CALLISTO\\\\Daily_Overview\\\\01-01-2022_to_06-30-2022\\\\Data\",\n",
    "        \"FC\":\"59\",\n",
    "        \"ID\":\"MUPK\",\n",
    "        \"dst\" : \"E:\\CALLISTO\\Daily_Overview\\\\01-01-2022_to_06-30-2022\\Plots_MUPK\"\n",
    "} \n",
    "daily = Daily_Overview(**arguments)\n",
    "list1 = daily.files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719869c",
   "metadata": {
    "code_folding": [
     0,
     5,
     10
    ]
   },
   "outputs": [],
   "source": [
    "class slice:\n",
    "        def __init__(self,**kwargs):\n",
    "               for key, value in kwargs.items():\n",
    "                  setattr(self, key, value) \n",
    "            \n",
    "        def find(self,name):#return root dir and name of a given file\n",
    "            for root, dirs, files in os.walk(self.path):\n",
    "                if name in files:\n",
    "                    return os.path.join(root, name) \n",
    "    \n",
    "        def slice_time(self):\n",
    "                slash = \"/\"\n",
    "#                 dirs = find_Data()    \n",
    "#                 fit_path = path1+myYear+slash+types+slash+category+slash+\"Data\"+slash+file_name+\".fit\"\n",
    "                file_name = os.path.splitext(self.file_name)[0]\n",
    "                path1 = self.path+slash+ \"Specific\"+slash+'plots_for_'+file_name\n",
    "                if exists(path1) == False:\n",
    "                    os.makedirs(path1)\n",
    "                fit_path = self.find(self.file_name)\n",
    "\n",
    "        \n",
    "                #join time axis\n",
    "                joined1 = pyc.PyCallisto.from_file(fit_path)\n",
    "                plt = joined1.spectrogram() #this will show in imshow thing\n",
    "                plt.savefig(path1+slash+\"simple_joined.png\")\n",
    "\n",
    "                # slice in frequency axis\n",
    "                freq_sliced = joined1.slice_frequency_axis(self.freq1,self.freq2)\n",
    "                plt = freq_sliced.spectrogram() #this will show in imshow thing\n",
    "                plt.savefig(path1+slash+\"freq_sliced.png\")\n",
    "\n",
    "                #do background subtraction\n",
    "                background_subtracted = freq_sliced.subtract_background()\n",
    "                plt = background_subtracted.spectrogram()\n",
    "                plt.savefig(path1+slash+\"bg_sub.png\")\n",
    "\n",
    "                #slice in time axis\n",
    "                time_sliced = freq_sliced.slice_time_axis(self.begin, self.end)\n",
    "                # time_sliced = freq_sliced.slice_time_axis(begin, end)\n",
    "                plt = time_sliced.spectrogram() #this will show in imshow thing\n",
    "                plt.savefig(path1+slash+\"time_sliced.png\")\n",
    "\n",
    "                #do background subtraction\n",
    "                background_subtracted = time_sliced.subtract_background()\n",
    "                plt = background_subtracted.spectrogram()\n",
    "                plt.savefig(path1+slash+\"time_sliced_bg_sub.png\")\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dda302",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Plot time and frequecy slice---\n",
    "params= {\n",
    "    \"path\" : \"E:\\CALLISTO\",\n",
    "    \"file_name\" : \"MUPK_20220417_140000_59.fit\",\n",
    "    \"begin\" : \"14:07:00\",\n",
    "    \"end\" : \"14:09:00\",\n",
    "    \"freq1\" : \"45\",\n",
    "    \"freq2\": \"200\"    \n",
    "}\n",
    "slice = slice(**params)\n",
    "slice.slice_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05a632",
   "metadata": {
    "code_folding": [
     0,
     1,
     5,
     28
    ]
   },
   "outputs": [],
   "source": [
    "class heatmap:   #Data availibility heatmap code---\n",
    "    def __init__(self,year, station):\n",
    "        self.year = year\n",
    "        self.station = station\n",
    "        \n",
    "    def files(self):\n",
    "        fs = []\n",
    "        fd = []\n",
    "        actual = []\n",
    "        for root, dirs, files in os.walk(r'E:\\\\'):\n",
    "             for file in files:\n",
    "                # check the extension of files\n",
    "                if file.endswith('.fit'):\n",
    "                    # print whole path of files             \n",
    "                    fs.append(file.split('_'))\n",
    "                    fd.append(file)\n",
    "                    actual.append(file.split('.'))\n",
    "        d = pd.DataFrame(fs)\n",
    "        ds = pd.DataFrame(actual)\n",
    "        d[3],d[4] = ds[0] , fd\n",
    "        d.drop(d.index[d[1].isnull()], inplace = True)\n",
    "        d[5] = pd.to_datetime(d[1]).dt.date\n",
    "        d[1] = pd.to_datetime(d[1] + d[2])\n",
    "        d.set_index(d[1],inplace = True)\n",
    "        d.drop_duplicates(subset=[4],inplace = True)\n",
    "        d =  d.between_time('00:30', '15:00')\n",
    "        return d \n",
    "    \n",
    "    def process(self):\n",
    "        ds = self.files()\n",
    "        df = pd.concat([ds[5], ds[0]], ignore_index=True, axis = 1)\n",
    "        station = df[df[1]==self.station]\n",
    "        station = station[0]\n",
    "        em = []\n",
    "        liste = []\n",
    "        month = ['01','02','03','04','05','06','07','08','09','10','11','12','13']\n",
    "        year = int(self.year)\n",
    "        for x in range(12): # filling with all the dates in a given year as a list\n",
    "            if x==11:\n",
    "                em.append(np.arange(self.year+'-'+month[x]+'-01',str(year+1)+'-'+month[0]+'-01',dtype='datetime64[D]'))         \n",
    "            else:            \n",
    "                em.append(np.arange(self.year+'-'+month[x]+'-01',self.year+'-'+month[x+1]+'-01',dtype='datetime64[D]')) \n",
    "\n",
    "        ds = pd.DataFrame(em)\n",
    "        ds = ds.fillna(1)\n",
    "        a = np.zeros((12,31))        \n",
    "        for m in range(12): # filling np.zeros array with number of data files per day\n",
    "            for d in range(31):\n",
    "                if ds[d][m] != 1:                    \n",
    "                     a[m][d] = station.loc[str(ds[d][m].date())].count()\n",
    "                     continue\n",
    "        return a    \n",
    "    def show(self):\n",
    "        data = self.process()\n",
    "        label_name = \"Day\" # x axis label\n",
    "        fig = px.imshow(data,\n",
    "                        labels=dict(x=label_name, y=\"Months\", color=\"No\"),\n",
    "                        x= list(range(0,31)),\n",
    "                        text_auto=True,\n",
    "                        y=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "                       )\n",
    "        fig.update_xaxes(side=\"top\")\n",
    "        fig.show()\n",
    "        return fig\n",
    "    def save_html(self, name, dst ) :\n",
    "        fig = self.show()\n",
    "        fig.write_html(dst+\"\\\\\"+name+\".html\")  \n",
    "        print(name +\"_\"self.year+ \".html is saved in : \"+ dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a90e4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Plot heatmap(args)\n",
    "# year = \"2022\"\n",
    "# station = \"SONPK\"\n",
    "# dst = \"E:\\\\CALLISTO\\\\Data availability\"\n",
    "# name = \"SONPK\"\n",
    "# heatmap = heatmap(year,station)\n",
    "# # heatmap.show()  \n",
    "# heatmap.save_html(name, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09b80b",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Advancement of temp file------> \n",
    "# import tempfile\n",
    "# import shutil\n",
    "# def temp_dir():\n",
    "#     with tempfile.TemporaryDirectory() as tmpdir:\n",
    "# #         print('Created temporary directory ', tmpdir)\n",
    "# #         os.path.exists(tmpdir)\n",
    "#         src = \"E:\\\\CALLISTO\\\\Daily_Overview\\\\2021\\\\2021-07-03\\\\MUPK_20210703_004500_59.fit\"\n",
    "#         dst = str(tmpdir)\n",
    "#         shutil.copy(src, dst)\n",
    "#         for root, dirs, files in os.walk(dst):\n",
    "#             print(files,tmpdir)\n",
    "\n",
    "        \n",
    "# temp_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac7bdb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Rename dir names wrt correct date format(YY,mm,dd)\n",
    "#os.chdir(r\"E:\\\\CALLISTO\\\\Daily_Overview\\\\01-01-2022_to_06-30-2022\\\\Data\\\\\")\n",
    "# liste = []\n",
    "# print()\n",
    "# for root, dirs, files in os.walk(os.getcwd()):\n",
    "#             liste.append(dirs)\n",
    "# # print(liste[0])\n",
    "# df = pd.DataFrame(liste[0])\n",
    "# liste = liste[0]\n",
    "# df[0] = pd.to_datetime(df[0])\n",
    "# df[0] = df[0].astype(str)\n",
    "# for x in range (len(df)):\n",
    "#     os.rename(liste[x],df[0][x])\n",
    " \n",
    "# print(liste[1], df[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.85px",
    "left": "656px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
